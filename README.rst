TorchRL
========

.. image:: https://travis-ci.org/activatedgeek/torchrl.svg?branch=master
    :target: https://travis-ci.org/activatedgeek/torchrl

.. image:: https://badge.fury.io/py/torchrl.svg
    :target: https://pypi.org/project/torchrl/

.. image:: https://img.shields.io/badge/status-beta-green.svg
    :target: https://pypi.org/project/torchrl/

.. image:: https://img.shields.io/pypi/pyversions/torchrl.svg
    :target: https://github.com/activatedgeek/torchrl

+-----------------------------------------------+---------------------------------------------------------+
| *Docs*: `<https://torchrl.sanyamkapoor.com>`_ | *Github*: `<https://github.com/activatedgeek/torchrl>`_ |
+-----------------------------------------------+---------------------------------------------------------+

*TorchRL* provides highly modular and extensible approach to experimenting with
Reinforcement Learning. It allows for a registry based approach to running
experiments, allows easy checkpointing, and updating hyper parameter sets.
All this is accessible via a programmatic interface as well as a friendly CLI.

Objectives
-----------

* Modularity in the RL pipeline
* Clean implementations of fundamental ideas
* Fast Experimentation
* Scalability
* Low bar and High ceiling

Install
--------

.. code:: shell

    pip install torchrl

Install from source for the latest changes that have not been published to PyPI.

.. code:: shell

    pip install https://github.com/activatedgeek/torchrl/tarball/master

This installs the ``torchrl`` package and the ``torchrl`` CLI.
